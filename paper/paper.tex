% 
% instead of saying lazy evaluation -- say how much time do we take 
% some quantification on how much time does it take to get 
% put challenges in introduction -- what does this make hard to solve? Put in the introduction. 
% intro, one line on contributions, and put challenges in the beginning. -- this will allow to motivate better (can use dag, say you will explaon)

% \para{application}: then application. Then a new para how our approach can be applied to the problem. Put the whole section at the end. Also put the references.

% Don't use quotes on very long sentences. 
% Put Javascrip Wasm section after Ethash. This section is too small. Do we really want it. 
% Talk about wasm in one place, not two. 

% remove pseudocode.
% Have a section of ethereum and define what block header and hash. Also define target etc 
% dEFINE epoch early on. 
% called Cache in ethereum terminology. Mention that the size of the cache varies right 
% define lightweight and full node earlier.
% Say each DAG consists of nodes and pages. Explain what 
% Ads: talk about how our approach can be applied to 

% our approach --
% how long -- our key contribution is to measure if this is viable to wait till the hash rate gets good. We need to mention this earlier. 
% remove `n'
% the video application. 
% Have a name. 
% its not clear that js was used. 
% have a para on js and webasm in our approach. 
% have the definitions before the claim. 
% use a different var for Hash and 
% put in the logs!!

% look at all citations -- at least there should be a year and conference. 
% more descriptive captions for figures.

% minimize the jargon
% experiments should reinforce what you say before.

% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{float}
\usepackage{graphicx}
% \usepackage{balance}
% \usepackage{color}
\usepackage{makecell}
\usepackage{amsmath}
% \usepackage{algorithmic}
\usepackage{amssymb}
\usepackage{caption}
\newcommand{\trishita}[1]{}%{{\color{magenta}\bfseries[Trishita: #1]}}
\newenvironment{claimproof}[1]{\par\noindent\underline{Proof:}\space#1}{\hfill $\blacksquare$}

% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}
\begin{document}
%
\title{Distributed Web Mining of Ethereum
% \thanks{Supported by organization x.}
}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{
Trishita Tiwari%\orcidID{0000-1111-2222-3333} 
\and
David Starobinski%\orcidID{1111-2222-3333-4444} 
\and
Ari Trachtenberg%\orcidID{2222--3333-4444-5555}
}
%
\authorrunning{T. Tiwari et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Boston University, Department of Electrical and Computer Engineering, Boston, MA 02215, USA \\
\email{\{trtiwari,staro,trachten\}@bu.edu}}
%
\maketitle             
%
\begin{abstract}
We consider the problem of mining crytocurrencies by harnessing the inherent distribution capabilities of the World Wide Web. More specifically, we propose, analyze, and implement \verb|WebEth|, a browser-based distributed miner of the Ethereum cryptocurrency. \verb|WebEth| handles Proof-of-Work (PoW) calculations through individualized code that runs on the client browsers, and thereafter collates them at a web server to complete the mining operation. \verb|WebEth| is based on an lazy evaluation technique designed to function within the expected limitations of the clients, including bounds on memory, computation and communication bandwidth to the server. We provide proofs-of-concept of \verb|WebEth| based on \verb|JavaScript| and \verb|WebAssembly| implementations, with the latter reaching hash rates up to roughly 40 kiloHashes per second, which is only 30\% slower than the corresponding native \verb|C++|-based miner.
Finally, we explore several applications of \verb|WebEth|, including monetization of web content, rate limitation to server access, and private Ethereum networks. Though several distributed web-based cryptominers have appeared in the wild (for other currencies), either in malware or in commercial trials, we believe that \verb|WebEth| is the first open-source cryptominer of this type.
% The process of legitimating cryptocurrencies (such as Bitcoin and Ethereum) is done
% through mining, often in a competitive and distributed manner by means of a small number of
% large, loosely-organized mining colonies following proprietary protocols.  We

% Cryptocurrencies such as Bitcoin and Ethereum are valdated and legitimated through mining,
% a competitive and often distri

% We propose and analyze an open-source platform for distributed cryptocurrency mining.  

% Given the seemingly endless growing popularity of crypto-currencies, there is an increasing interest in different mining possibilities. This paper proposes a web browser based mining implementation for Ethereum implemented both in JavaScript and WebAssembly to perform the necessary Proof-of-Work (PoW) computations to mine the Ethereum blockchain. We explore a lazy evaluation based technique to distribute the inherently memory and memory intensive PoW of Ethereum over multiple browser-based clients that have limited resources. We obtain the best results with the WebAssembly implementation, with hash rates reaching upto 39651H/s ~\trishita{Not sure if we need such a specific number}, which, as we demonstrate, is merely 30.2\% slower than a native miner that uses the same algorithm for mining under the same conditions. We show that this solution is practical for a variety of purposes, such as web content monetization, web based authentication rate limiting and private Ethereum networks.


\keywords{crypto-currency \and Ethereum \and distributed computing \and web-browser computing \and mining}
\end{abstract}
%
%
%
\section{Introduction}
Cryptocurrencies are increasingly gaining traction as a viable form of currency.  This has been accompanied by a correspondingly increasing interest in the efficient validation (or \emph{mining}) of cryptocurrency transactions.  Whereas initial efforts in this domain have focused on creating dedicated hardware for this task ~\cite{asics}, %AT - citation needed
\trishita{Add citation}
more recent approaches have examined repurposing existing infrastructure. Indeed, one such class of efforts has focused on the use of client web browsers as a platform for distributed computing~\cite{Cushing}. The growing popularity of CoinHive~\cite{coinhive} is a case in point of the potential success of distributed in-browser cryptocurrency mining as a commercial (if malicious) enterprise. 

In this work, we propose \verb|WebEth|, a browser-based distributed miner for the popular Ethereum block chain~\cite{ethereum}. \verb|WebEth| tackles the challenge of achieving a profitable hash rate within a distributed ensemble of browsers under constrained memory, computation and network usage. Indeed, every browser needs to store a data structure of at least 1~GB in memory in order to mine Ethereum. Clearly, it is unfeasible to transfer this entire data structure every time a browser loads a web page. Instead, \verb|WebEth| employs an lazy approach to generating this data structure while mining. Through our experiments, we show that this approach takes at most five minutes to reach a steady state hash rate -- making it ideal for web applications where users spend time, such as gaming and video streaming. Our experiments also show that \verb|WebEth| yields a hashing rate of up to 40 kiloHashes/s, which, despite the overhead from running the algorithm in a browser, is only 30\% smaller than the performance of a corresponding miner running natively. 

%\subsection{Our Contributions}
%In this work, we explore the web-based cryptocurrency mining of the popular Ethereum block chain, % %\trishita{Add citation}%AT - citation needed
%and propose a number of potential applications consequent to this platform.  

The main contributions of this work are as follows:
\begin{itemize}
\item We propose \verb|WebEth| \cite{WebEth}, an open-source implementation of a distributed web-based Ethereum cryptominer in both \verb|JavaScript| and \verb|WebAssembly| that can operate under relatively resource constrained environments. Though miners for other currencies exist in the wild (e.g. CoinHive~\cite{coinhive}), they are all proprietary and closed-source.
\item We provide theoretical analysis and experimental evidence of the potential efficacy of the lazy approach adopted by \verb|WebEth| to achieve high hashing rates.
%\trishita{I feel like this next part is repetitive}Our miner employs an lazy approach to mining that takes $\approx$ 5 minutes for it to reach its maximum hash rate. In addition, we show that our \verb|WebAssembly| implementation can provide hash rates up to 40 kiloHashes/s, which is only 30\% smaller than the hash rate provided by a native C++ miner that employs the same algorithm.
\item We propose a number of potential applications built upon \verb|WebEth|, including rate-limiting server access, usage tracking, and content monetization.
\end{itemize}

% Our research involves providing implementations of a distributed, web browser based Ethereum miners in \verb|JavaScript| and \verb|WebAssembly|, and studying whether or not it is feasible for real world purposes. While there has been prior academic work done in related fields, none of the distributed web browser implementations in these works involve crypto-currency mining. While CoinHive does perform distributed mining using web browsers, it is closed source, and also works with a different crypto-currency (Monero). Hence, we are pioneers in offering an open source architecture for Ethereum mining with web browsers. Our miner gives us a hashrate of about 39kH/s, which, given the versatility of the Ethereum framework, is useful and practical for many applications like web authentication rate limiting, website usage tracking for advertisement companies, private Ethereum networks, web content monetization, as discussed below.

% \subsection{Applications}

\paragraph{Related Work}
Distribution of a common task is hardly a new concept~\cite{scheduling,parallel,orca}, but the growing popularity and efficiency of dynamic web content and client-side scripting languages like \verb|JavaScript| and \verb|WebAssembly|
have made web browsers an enticing implementation option~\cite{WebFlow,Duda,Cushing}.  Coinhive~\cite{coinhive} has
built into this environment a proprietary method for mining the Monero cryptocurrency, but this is often done on
the browsers of unsuspecting users.  A more ethical, open-sourced alternative, the Basic Attention Token~\cite{basicAttentionToken}, is an Ethereum-based ERC20 token~\cite{erc20} currently in development to be used in conjunction with the Brave browser~\cite{BraveBrowser} to generate ad revenue for website publishers by \emph{measuring a user's attention} on an advertisement. This platform promises to balance the ties between website users, publishers, and advertisers to ensure that users get only ads they would accept, advertisers pay for actual users (instead of click bots), and publishers actually get revenue instead of begging users to turn off their ad blockers.

% So far, there has been quite a lot of work done on distributed systems ~\cite{scheduling,parallel,orca}. Additionally, with the growing popularity of dynamic web-content and client side scripting languages like \verb|JavaScript| and \verb|WebAssembly|, web-browsers have also become a lucrative option for implementing distributed systems. As such, there has been some work done in exploring this relatively new avenue ~\cite{WebFlow,Duda,Cushing}. 
% Indeed, ``Distributed Computing on an Ensemble of Browsers'' by Cushing~\cite{Cushing} shows that the \verb|JavaScript| Engine has had enough improvements in performance to make computationally heavy programs feasible in a distributed web browsing unit. 
% In addition, the work by Duda and Dłubacz~\cite{Duda} was instrumental in the field as one of the first web browsing computational systems to not require the host machine to install any additional applications in order to participate. This is important since we would want our web miner to be operable without requiring the user to install any unfamiliar software. 
% Furthermore, \verb|WebAssembly|  ~\cite{webAssembly} is one of the newest platforms intended for CPU intensive browser computing (such as image rendering), and claims to be only 20\% slower than native code ~\cite{wasmPerf}, as compared to the much slower \verb|JavsScript|. Instead of relying on \verb|JavaScript|, web developers can now write C/C++ and compile it into \verb|WebAssembly| using some of the openly available \verb|WebAssembly| compilers ~\cite{emscripten}. Indeed, given that now \verb|WebAssembly| is supported by all major browsers ~\cite{webAssembly}, industry is also making use of this powerful framework. 

% One sees the growing popularity of distributed web computation through the recent development of increasingly popular Monero mining library CoinHive~\cite{coinhive}. In terms of the potential monetization aspect of the project, there exists an ethical alternative to CoinHive called the Basic Attention Token ~\cite{basicAttentionToken}. The Basic Attention Token is an ERC20 Token built on Ethereum that is used along with the Brave browser to generate Ad revenue for website publishers by measuring a user's attention span on an advertisement. Note that this is not a replacement for Ad revenue, but a platform to balance the ties between website users, publishers, and advertisers. It ensures that users get only ads they would accept, advertisers pay for actual users instead of click bots, and publishers actually get revenue instead of pleading the users to turn off their Ad blockers.

\paragraph{Roadmap}
The remainder of the paper is organized as follows. In Section 2\ref{sec:background} we cover the relevant background and related literature for our work.  In particular, we provide a self-contained description of Ethash, the Ethereum mining Proof-of-Work (PoW), and \verb|WebAssembly|, the language in which we implement an efficient miner. Section 3\ref{sec:webeth} describes \verb|WebEth|, including its lazy approach to distributing the Ethash PoW over numerous, resource-constrained browsers. This section also includes a performance analysis. We present the experimental results of our implementations in Section 4\ref{sec:results}. In Section 5\ref{sec:applications} we discuss several potential applications of our mining platform. We conclude in Section 6\ref{sec:conclusion}.  

\section{Background}
\label{sec:background}
\subsection{Cryptocurrencies: a general overview}
Most cryptocurrencies like Ethereum involve storing transactions in blocks, and the entire history of transactions is collated in a data structure known as a block chain. The block chain is managed by dedicated machines called \emph{client nodes}; where each client node typically stores the entire block chain. However, because each client node operates on its own copy of the block chain, the block chains on different nodes may go out of sync. Hence, there needs to be an accepted mechanism to decide the order in which new transaction blocks are appended to this block chain. 
For this, every time a new transaction takes place, the transaction is pooled together with all other transactions that have been broadcasted to the network, but haven't been added to the block chain yet. For most currencies, the data structure that stores these unconfirmed transactions is known as the \emph{mem pool}. A miner picks valid transactions from his mem pool and creates a new block out of these transactions. Once this happens, the goal of the miner is to have his/her block appended to the block chain, which is achieved through a process called \emph{mining}.
% This block chain is operated on by the Ethereum Virtual Machine (EVM) ~\cite{EVM}, which, unlike Bitcoin Script, is Turing Complete ~\cite{turingComplete}. 
% Furthermore, this currency is also a Proof-of-Work based currency, which means that the new blocks are appended to the block-chain through a process called ``mining''. 
Mining involves a race amongst miners to solve a \emph{Proof-of-Work} (PoW) puzzle, which is usually an energy intensive computation. The winner of this race gets to have his block appended to the block chain. The winner also receives a payout, which acts as an incentive to mine. 
% This process of mining is essential to deciding the order in which transactions are appended to the inherently decentralized block-chain, thereby stabilizing the chain. 
Ethereum uses Ethash as its PoW algorithm, which is explained in detail below.

\subsection{Ethereum Proof of Work}
Ethereum is a crypto-currency that was released in July 2015 by Vitalik Buterin, Gavin Wood and Jeffrey Wilcke. Ethereum uses the Ethash algorithm (derived from the Dagger and Hashimoto algorithms ~\cite{dagger-hashimoto}) for its PoW for mining blocks. Before we discuss how mining works with Ethash, we first establish basic terminology about the data structures involved in the PoW.

A \emph{block header} contains meta-data related to the transactions of the corresponding block, and it is provided as an input to the Ethash algorithm together with an integer \emph{nonce}.  The nonce is chosen in a brute-force fashion in order to hash, together with the block header, into a value that matches a specific pattern (based on a predefined \emph{difficulty threshold}). The process of finding an appropriate nonce for a given block is known as \emph{mining}.
%\item \textbf{Difficulty Threshold}: An integer value below which the hash digest output of Ethash should be in order for the miner to have successfully mined the block.

Once a block has been mined, it is propagated to other client nodes so that they can update their copies of the block chain. However, before each client node does so, it must validate whether the miner is submitting a legitimate block -- i.e., check whether the miner genuinely solved the hash as claimed. This is easily done by putting the block header and nonce associated with the block through the Ethash algorithm and checking whether the output follows the pattern prescribed by the difficulty threshold.  \emph{Light weight} client nodes do not mine new blocks, but rather only verify whether any new block submitted by a miner is valid or not.  \emph{Full} client nodes, on the other hand, both mine and verify new blocks.

An \emph{epoch} is a unit of ``time'' that spans 30,000 blocks.  All of the data structures in Ethash (mentioned below) need a 256 bit \emph{seed}, which differs for every epoch. For the first epoch the seed is a Keccak-256~\cite{keccak} hash of a series of 32 bytes of zeros. For every other epoch it is always the Keccak-256 hash of the previous seed hash.  The seed for a particular epoch is used to compute a data structure known as the \emph{Cache}, which is an array of 4 byte integers \cite{Ethmining}. The Cache production process involves using the seed hash to first sequentially fill up the Cache, then performing two passes of the RandMemoHash algorithm~\cite{randmemohash} on top of it to get the final Cache value. 
% This transforms the initial cache to give us the final value for the cache. 
Light weight clients may use this Cache for verifying hashes, while full node clients can use it to calculate a Directed Acyclic Graph (DAG) dataset, as described below.  A Ethereum \emph{Directed Acyclic Graph} is stored as a large byte array (around 1 GB in size on the private Ethereum Network used for our experiments) and has the following two attributes:
  \begin{enumerate}
  \item \emph{Node}: Each DAG node in this byte array spans 64 bytes, and node indices are therefore aligned at a 64 byte boundary.
  \item \emph{Page}: Each DAG page spans 2 nodes, however, page accesses are not aligned at a 2 node boundary. The mining process involves accessing some DAG pages and hashing them together with the block header and nonce.
  \end{enumerate}
Each node in the DAG is generated by combining data from 256 pseudo-randomly selected Cache nodes and hashing them together. This process is repeated to generate all nodes in the DAG. Finally, intermediate byte arrays used to store temporary results in the Ethash algorithm are known as \emph{Mix}es.

We must point out that as time goes on, mining Ethereum becomes more and more difficult, as the size of the Cache and DAG increases with every epoch. 

\begin{figure}[h]
\centering
\includegraphics[width=300px,keepaspectratio]{Ethash.pdf}
\caption{Ethash}
\label{fig:ethash}
\end{figure}

Mining is performed by starting with the current block header hash and nonce, which are combined to get a 128-byte wide Mix, as seen in step 1 of Figure 1\ref{fig:ethash}. The Mix is then used to fetch a specific page of the DAG from memory. After this, the Mix is updated with the fetched page of the DAG (step 2). Then, this updated Mix is used to fetch a new page of the DAG (step 3). This process of sequentially fetching parts of the DAG is repeated 64 times (step 4), and the final value of the Mix is put through a transformation to obtain a 32 byte digest (step 5). This digest is then compared to the threshold (step 6). If it is smaller than the threshold, the nonce is valid and the block is successfully mined and can be broadcast to the network. However, if the digest is greater than the threshold, the nonce is unsuccessful, and the entire process must be repeated with a new nonce~\cite{Ethmining}. 

% Below is the pseudo-code for the algorithm for completeness.\\
% \begin{algorithmic}[H]
% \label{miningAlgo}
% \STATE $mix \gets mixInit(\{header,nonce\})$
% \FOR{$i = 0;\;i < 64;\;i++$}
%   \STATE $dagPageIndex \gets getDAGPageIndexFromMix(mix)$
%   \STATE $dagPage \gets DAG[dagPageIndex]$
%   \STATE $mix \gets updateMix(dagPage,mix)$
% \ENDFOR
% \STATE $digest \gets postProcessFunction(mix)$
% \IF {$digest <= targetThreshold$}
% 	\RETURN \TRUE
% \ENDIF
% \RETURN \FALSE
% \end{algorithmic}

It is important to note that the pages of the DAG that are used to compute the hash for a particular block depend on the nonce used, hence there is no way to pre-determine which pages will be useful to have in memory. This therefore forces miners to store entire DAG in memory, making Ethereum mining ``Memory Hard''. 

% This is intended to even the playing field, as ASIC miners no longer have any advantage as they do for Bitcoin. GPU miners, however, do have an advantage, normally having hashrates of over 10 times that of a CPU miner.

Whereas mining is memory intensive, verification is relatively lightweight. This is because of the property that each node in the DAG depends on a set of pseudo-randomly selected items from the Cache. Hence, the Cache is used to regenerate only the specific pages of the DAG that are needed to recalculate the hash for the particular nonce. And so, only the Cache needs to be stored by light weight clients that only perform verification. In fact, as we will see in the next section, we use this property of being able to generate parts of the DAG as needed to our advantage in order to alleviate some of the memory and network bandwidth restrictions that browsers typically face.

\subsection{JavaScript and WebAssembly}
Introduced in 1995 by Netscape Communications Corporation~\cite{js}, \verb|JavaScript| was a meant to be a light scripting language in order to  make web content dynamic. Over the span of 23 years, it has grown to become one of the most popular client-side web development languages used to make dynamic user interfaces. 

In fact, up to recently, \verb|JavaScript| has been the only language available to make dynamic client-side web content. However, the situation has changed since the advent of \verb|WebAssembly| in 2016. As per its creators, \verb|WebAssembly| is a ``binary instruction format for a stack-based virtual machine'' \cite{webAssembly}. WASM is designed to be compiled from high-level languages like \verb|C/C++/Rust|, and is supported by 4 major browser platforms -- Firefox, Safari, IE, and Chrome \cite{webAssembly}. The \verb|WebAssembly| stack machine is designed to be encoded in a ``size-and load-time-efficient binary format''~\cite{webAssembly}, and aims to execute near native speed by utilizing common hardware capabilities present on a wide variety of platforms~\cite{webAssembly}. The language is meant to improve performance for computationally intensive use cases such as image/video editing, games, streaming, etc~\cite{webAssembly}. This makes it the language of choice to implement a miner within a browser. 

%\subsection{Challenges}
%The crux of having a good hashrate for Ethereum lies in having quick access to the DAG. One of the biggest challenges with mining on a distributed ensemble of browsers is to transfer and store this data structure within each worker browser. However, given that the DAG for an Ethereum network is at least 2 GB (and growing), transferring it to the browser every time a client loads our web page is impractical. Furthermore, even if one somehow manages to transfer the DAG to the client when the web page loads, the browser still has to store the DAG in memory, thereby using a sizeable amount of resources on the client machine. In section~\ref{sec:approach} we discuss approaches to tackle some of these challenges.

\section{WebEth}
\label{sec:webeth}
%\label{sec:approach}
%\subsection{Approach}
% \trishita{I think it would be nice if we show how we modified the algorithm shown in the previous section. I will add that over here}

\verb|WebEth| is based on a lazy evaluation to alleviate the network and memory requirements for mining Ethereum in a distributed scenario on browsers. Specifically, as soon as each browser connects to the webserver, the server sends to the browser the current header of the block being mined and the Cache. Once the browser receives the Cache, it allocates an array buffer to store the DAG node.
%s that fall between indices 0 and $N$ that will be computed in the future. (Note that the $N$ is a variable parameter reflecting the length of the buffer with which we experiment in our analysis). 
Once the buffer is allocated, the browser can start iterating over nonces to compute hashes.  

Since, to begin with, the browser does not store any nodes of the DAG, it must compute each node on the fly using the Cache. However, every node that the browser computes is stored in the buffer, for quicker access in the future. Hence, as time passes, the buffer starts filling up, such that more and more nodes are quickly accessed from the buffer rather than being computed from the ground-up, which makes hash computations faster with time. This has the effect that the longer the user remains on the web-page, the better the hash rate gets for that user.

% Our modified algorithm is shown below:

% \begin{algorithmic}[H]
% \label{modifiedMiningAlgo}
% \STATE $mix \gets mixInit(\{header,nonce\})$
% \FOR{$i = 0;\;i < 64;\;i++$}
%   \STATE $dagPageIndex \gets getDAGPageIndexFromMix(mix)$
%   \STATE $dagPage \gets DAGbuffer[dagPageIndex]$
%   \IF {$dagPage == NULL$}
% 		\STATE $dagPage = computeDAGPageFromCache(dagPageIndex)$
%         \STATE $DAGbuffer[dagPageIndex] = dagPage$
%   \ENDIF  
%   \STATE $mix \gets updateMix(dagPage,mix)$
% \ENDFOR
% \STATE $digest \gets postProcessFunction(mix)$
% \IF {$digest <= targetThreshold$}
% 	\RETURN \TRUE
% \ENDIF
% \RETURN \FALSE
% \end{algorithmic}


\subsection{Implementation}
% \begin{figure}[H]
% \centering
% \includegraphics[width=250px,keepaspectratio]{miningpool.png}
% \caption{\label{fig:miningpool} Distributed Ethereum Mining}
% \end{figure}

The \verb|WebEth| architecture is centered around a central node and client-side Ethereum miners. We have two implementation for client-side miners: in \verb|JavaScript| and in \verb|WebAssembly|. 

The central node coordinates all workers (browsers). Its implementation is based on a modified version of \verb|geth| \cite{geth}, a real world Ethereum miner written in \verb|Go|. \verb|geth| typically runs as a standalone miner that mines on the machine on which it is running. We modify the code so that instead of doing all the mining all by itself, the node sends over the necessary data (namely, the hash of the block header and the Cache) to any client that connects to it on port \verb|9000|. After receiving the necessary data, each browser allocates a buffer for the DAG in order to store future DAG nodes. Note that the buffer for the DAG is implemented as an array of ints, so as to make each lookup in the buffer constant in time. At this point, the client-side miner can begin to search for a solution. 

For our miner, we model the \verb|JavaScript| implementation after the ~\verb|node.js| implementation of Ethash~\cite{ethash}. The \verb|WebAssembly| version is the \verb|JavaScript| version transpiled to \verb|C++|, which in turn is compiled to \verb|WebAssembly| using the ~\verb|Emscripten| compiler~\cite{emscripten}. 

At the beginning, the miner creates a random nonce and computes the hash (using the Cache and the buffered DAG) as discussed in the previous section. It continues to perform this action on new nonces until one of two following scenarios occur. 

In the first scenario, the miner finds a nonce such that the computed hash is below the given threshold. In that case, the browser submits the result back to the central node and then asks the central node for the new block header and the Cache. 

In the second scenario, the algorithm times out without finding a result. In that case, the miner polls the central node for the current versions of the block header and Cache and continues to mine using the new inputs. This process continue until the user moves away from the website or closes the browser. 
This time out is necessary since the browser should work with the most recent block header and Cache. The block header can become stale if that particular block has already been mined, and the Cache can become stale if the Ethereum network transitions into a new epoch (this happens once every 30,000 blocks). 

Finally, we must point out that both our current implementations in \verb|JavaScript| and \verb|WebAssembly| require no external dependencies, and therefore can be directly embedded into any website. For a diagrammatic view our our design, see Figure 2\ref{fig:hybridArchitecture}.

\begin{figure}[h]
\centering
\includegraphics[width=230px,keepaspectratio]{Hybrid-Miner.pdf}
\caption{Web Miner Architecture}
\label{fig:hybridArchitecture}
\end{figure}

\subsection{Performance Analysis}
In this section, we perform a back-of-the envelope calculation for the number of hashes needed till \verb|WebEth| fills up almost all the buffer. This is important because the hash rate reaches its maximum steady-state only once the buffer in the browser is almost full. Specifically, we show that filling a buffer the size of the DAG up to 99.9999995\% should take on average about 3.7 million hashes, while filling up 99.5\% of this buffer takes much lesser -- about 1.4 million hashes. 
The approach we take is based on the Coupon Collector problem~\cite{couponCollector}. 

For simplicity, we assume that nodes in the DAG are randomly sampled in order to compute a hash, whereas, in reality, this is not entirely true, because two neighboring DAG nodes are computed for each page computation (rather than a single node). Hence, in order to account for this simplification we also assume that 64 DAG \textbf{nodes} are used for each hash computation instead of 64 \textbf{pages} (or 128 nodes), and so our results suggest that it should take more hashes to fill the buffer up than it would in real life.
% For simplicity, we assume that the DAG is randomly sampled in order to compute hashes. In reality, this is not entirely true, because two neighboring DAG nodes are computed for each page computation (rather than a single node).  Hence, the results we obtain from the following analysis are more conservative than those observed in practice. 

%In fact, while we show here that filling up 99.5\% of a buffer as big as the DAG takes 1.4 million hashes, whereas in reality it only takes half as many hashes, as shown in Section~\ref{sec:results} \\

% time: 272364.700001
% glue.js:1 num Hashes: 1270782
% glue.js:1 cache hit: 0.999990
% miner.js:105 Client hashes average hashrate: 0

% c 1370000:  0.999972
% glue.js:1 h 1370000:  49975.012494

For our analysis, we introduce the following notation. We denote by $N$ the total number of nodes in the DAG, by $a$ the number of DAG nodes needed to compute a hash, by $\delta$ the failure probability of finding a specific node in the buffer (i.e., the buffer miss rate), by $\omega$ the failure probability of computing a hash using nodes already stored in the buffer, by $E(X)$ the expected number of hashes to fill the buffer with a failure probability $\delta$, and by $H_n$ the $n$-th Harmonic number~\cite{harmonicNumber}.
\begin{claim}
For $\delta \ll 1$, $E(X) \approx \frac{N}{a}(H_{N} -H_{N\delta}).$
\end{claim}

\begin{claimproof}
The number of nodes needed in the buffer to achieve a node failure probability $\delta$ is 
$\left \lfloor{N(1-\delta)}\right \rfloor$.  %= Nf_1(1-\frac{\omega}{a})
This means that even though we are allocating a buffer that can hold $N$ pages, we are willing to forgo $\left \lfloor{N\delta}\right \rfloor$ nodes (to simplify notation, from now and on, we assume $N\delta$ is an integer).  

Using results from the Coupon Collector's problem~\cite{couponCollector}, we know that the expected number of trials for obtaining the $i$-th new node after having buffered $i-1$ nodes is $N/(N-(i-1))$.
Thus, the expected number of trials in order to fill up the buffer with ${N(1-\delta)}$ nodes is given by
\begin{gather}
	E(t) = N\sum_{i=1}^{N(1-\delta)} \frac{1}{N-i+1}.
\end{gather}
Splitting this expression into two sums, we get
\begin{gather}
	E(t) = N \left(\sum_{i=1}^{N}\frac{1}{N-i+1} - \sum_{i=N(1-\delta)+1}^{N}\frac{1}{N-i+1} \right), 
\end{gather}    
or
\begin{gather}
    \label{eq:expectedTrials}
    E(t) = N(H_{N} -H_{N\delta})
\end{gather}
We now relate the failure probability  of calculating a hash using nodes already stored in the buffer  $\omega$ with the failure probability of having a specific node in the buffer $\delta$. By the independence assumption,
$$ (1-\delta)^a = 1-\omega.$$For $\delta \ll 1$, we have $(1-\delta)^a \approx 1-a\delta$. Hence,
\begin{gather}
    \label{eq:deltaomega}
	\delta \approx \frac{\omega}{a}.
\end{gather}
Hence, it follows from Equation~(4\ref{eq:deltaomega}) that 
\begin{gather}
	\label{eq:hashvspage}
	E(X) \approx \frac{E(t)}{a}.
\end{gather}
Finally, from Equations~(3\ref{eq:expectedTrials}) and~(5\ref{eq:hashvspage}) and, we obtain
\begin{gather}
    \label{eq:expectedHashes}
	E(X) \approx \frac{N}{a}(H_{N} -H_{N\delta}).
\end{gather}

\end{claimproof}

We use the following bounds on the Harmonic Numbers~\cite{harmonicNumber} to compute  Equation~(6\ref{eq:expectedHashes}):
\begin{gather}
    \label{eq:boundHarmonic}
	-\frac{1}{12n^2+{2\frac{7-12\gamma}{2\gamma-1}}}\le H_n-\ln n-\frac1{2n}-\gamma<-\frac{1}{12n^2+\frac{6}{5}},
\end{gather}  
where $\gamma = 0.57721566...$ is the Euler-Mascheroni constant.
% -\frac{1}{12n^2+{2(7-12\gamma)}/{(2\gamma-1)}}\le H(n)-\ln n-\frac1{2n}-\gamma<-\frac{1}{12n^2+6/5}

Specifically, using Equations~(6\ref{eq:expectedHashes}) and~(7\ref{eq:boundHarmonic}), and setting $N = 16777186$ (the number of nodes in the DAG for our experiments), $a = 64$ and $\delta = 0.000000005$, we get $E(X) \approx 3.7$ million hashes. However, if we increase $\delta$ to 0.005, we get $E(X) \approx 1.4$ million hashes. Hence, we see that even computing merely 1.4 million hashes fills a DAG buffer as large as the entire DAG by more than 99.5\%, as opposed to calculating 3.7 million to fill it by 99.9999995\%. 
% This suggests that the fuller the buffer is, the marginal cost of computing more hashes outweighs the rate at which the buffer is filled up. 
In fact, as we will see in the results, filling up 99.5\% of a buffer as large as the DAG already starts giving us good hash rates for a browser -- 35kH/s for the \verb|WebAssembly| miner. This shows that we need to have the buffer almost -- but not completely -- full in order to do well in terms of hash rates. And as we have seen, making the buffer almost full is not nearly as hard as filling it up entirely. 
This means that reaching a reasonably steady state is not as hard as it seems at face value, making \verb|WebEth| viable for web settings where users might not stay on websites for long. 

\section{Results}
\label{sec:results}
\subsection{Experimental set up}
Our experimental set up consisted of a machine with an Intel i7-7700HQ processor with 8 cores and 16GB ram. These results were obtained from a private Ethereum test network at epoch 0. The DAG size was 16777186 nodes (1.074GB). The cache size was 1.677MB. We ran the implementations in ~\verb|JavaScript| and ~\verb|WebAssembly| in the browser, and a native miner written in ~\verb|C++| that employs the same lazy evaluation approach outside of the browser for control results. Each miner was run till 800k hashes were computed and the hash rate and buffer hit rate were sampled every 10k hashes. (Note that both the hash rate and buffer hit rate sampled at a particular time reflected the values over the 10k most recent hashes).

\subsection{Implementation Results}
Figures 4\ref{fig:hashRateHMWASM},5\ref{fig:hashRateHMJS} and 6\ref{fig:hashRateHMNative} below shows a heat-map of how the hash rate varies for each of the three implementations as a function of both the size of the buffer allocated to store the DAG (as a percentage of the size of the entire DAG) and the number of hashes computed in the browser. Further, Figure 7\ref{fig:HitRateHM} then shows a heat-map of how the DAG buffer hit-rate varies as a function of both these parameters. 
As expected, both the hash rate and the buffer hit rate increases with the buffer size and the number of hashes computed for all three miners. We must also note that the experimental results suggest that it takes 70 kHashes to reach a buffer hit rate of 99.5\%, which falls well within our conservatively predicted value of 1.4 million hashes. In fact, we can validate that our experimental results are in agreement with the predicted results for all other hit rates as well.
% In fact, the number of hashes computed 

\begin{figure}[h]
\centering
\includegraphics[width=200px,keepaspectratio]{All_Miners_Hash_Rate.pdf}
\caption{All Miners' Hash Rate}
\label{fig:HashRateTraj} 
\end{figure}

\begin{figure}[t]
       \centering
    \makebox[\textwidth][c]{
    \begin{minipage}{.5\textwidth}
       \centering
  \includegraphics[width=\linewidth]{WebAssembly_Miner_Hash_Rate_HM.pdf}
\caption{WASM Miner $\log(Hash Rate)$}
\label{fig:hashRateHMWASM}
   \end{minipage}
       \begin{minipage}{.5\textwidth}
       \centering
    \includegraphics[width=\linewidth]{JavaScript_Miner_Hash_Rate_HM.pdf}
\caption{JS Miner $\log(Hash Rate)$}
\label{fig:hashRateHMJS}
    \end{minipage}}
\end{figure}

In order to closely examine the relationship between the hash rate and the hit rate, we show the correlations between the two parameters for all 3 miners in Figure 3\ref{fig:HashRateTraj}. It is interesting to see how the hash rate drastically spikes after the hit rate surpasses 95\%. This suggests that accessing DAG pages from the buffer is orders of magnitude faster than computing them, so much so that even a few computations bring down the hash rate drastically. Most importantly, from the experiments, the time it takes to reach this steady state hash rate not long (on the order of $\approx$ 5 minutes) thereby making this approach ideal for streaming/gaming websites. Furthermore, \verb|WebEth| is also ideal as a web miner as it is not very resource intensive -- throughout the experiments, it did not use more than 12.5\% of the CPU of our testing machine (the utilization value is normalized over 8 cores).

One might think that a way to reach the steady state hash rate faster for a given sized buffer would be to start out with a partially filled out buffer instead of an empty one. The only way this could work is by sending over part of the DAG over the network to the client. However, as it turns out, this is not feasible since, for a DAG with 16777186 nodes (1.074 GB) sending even 10\% of the DAG would be sending $\approx$ 100MB of data. With the global average download speed for desktops and smartphones being around 5.34MBps and 2.77MBps respectively~\cite{internetSpeed}, the web page load time would be in the order of 20 seconds to a minute -- which is too long to get a mere 10\% boost in the buffer storage. 

% The jump in the hash rate for high buffer hit rates is also seen in Figure~\ref{fig:HashRateTraj} where we show the correlations between the buffer hit rates and the hash rates for all 3 miners. The general trend is the same for all 3 miners -- the hash rate spikes up as the hit rate surpasses 95\% (Note that the hit rate gets extremely close to 1 but never quite reaches there, since we only compute 800k hashes as opposed to the 4.5 million would be needed as per our theoretical analysis).

\begin{figure}[t]
\captionsetup{justification=centering}
       \centering
    \makebox[\textwidth][c]{
    \begin{minipage}{.5\textwidth}
       \centering
  \includegraphics[width=\linewidth]{Native_C++_Miner_Hash_Rate_HM.pdf}
  \caption{Native C++ Miner $\log(Hash Rate)$}
  \label{fig:hashRateHMNative}
   \end{minipage}
       \begin{minipage}{.5\textwidth}
       \centering
    \includegraphics[width=\linewidth]{All_Miners_Buffer_Hit_Rate.pdf}
    \caption{All Miners' Hit Rate}
    \label{fig:HitRateHM}
    \end{minipage}}
\caption{Log(Hash Rate) and Hit Rate as a function of number of Hashes computed and Buffer Size}
\end{figure}

Table 1\ref{table:perf} shows us how the performance of each of the miners compare. Interestingly, the most conspicuous aspect is the fact that the performance variation between different implementations is not uniform across different buffer sizes and hit rates. We also see that for obvious reasons, the native miner outperforms both the~\verb|JavaScript| and the ~\verb|WebAssembly| miner. However, we see that the ~\verb|WebAssembly| miner is at most 40.5\% slower than the native miner -- which is not very far off considering the overhead of running programs within browsers. The \verb|JavaScript| miner, on the other hand, is \textbf{at least} 47.2\% slower (and at most 82.0\% slower), making \verb|WebAssembly| the better of the two candidates for \verb|WebEth|.

\begin{table}[t]
\caption{Performance variations across different Implementations}\label{table:perf}
\vspace{-2ex}
\begin{center}
\begin{tabular}{ l  c  c  c}

&\makecell{\textbf{WASM/JS}} & \makecell{\textbf{Native/JS}} & \makecell{\textbf{Native/WASM}}\\
\cline{2\ -2} \cline{3\ -3} \cline{4\ -4}
\% Diff in smallest hash rates & 35.9\% &  55.0\% & 38.9\% \\
\% Diff in peak hash rates & 73.2\% &  81.3\% & 30.2\% \\
Min perf \% diff &  24.4\% &  47.2\% & 23.9\% \\
Max perf \% diff  &  73.3\% &  82.0\% & 40.5\%\\ 
Avg. Hash Rate \% diff\\
\qquad  (averaged over all buffer sizes\\
\qquad  and buffer hit rates)&  30.6\% &  55.6\% & 35.9\%\\
\end{tabular}
\end{center}
\vspace{-3ex}
\end{table}


Finally, we tabulate the most important results from our analysis in Table 2\ref{table:results}.

\begin{table}[t]
\caption{Main Results}\label{table:results}
\vspace{-2ex}
\begin{center}
\begin{tabular}{ l  c  c  c}

&\makecell{\textbf{Native}} & \makecell{\textbf{JavaScript}} & \makecell{\textbf{WebAssembly}}\\
\cline{2\ -2} \cline{3\ -3} \cline{4\ -4}
\makecell[l]{Median Hash Rate \\
\qquad(for a buffer the size of the DAG)} & 15278H/s &  5290H/s & 10504H/s \\
Peak Hash Rate &  56800H/s &  10626H/s & 39651H/s \\
\makecell[l]{Time taken to 99.76\% \\ buffer hit rate}  &  163.601s &  879.857s & 257.7692s\\ 
\makecell[l]{Avg. Hash Rate \% diff with Native Miner \\
\qquad(averaged over all buffer sizes)}&  NA &  55.6\% & 35.9\%\\
\end{tabular}
\end{center}
\vspace{-3ex}
\end{table}

\section{Potential Applications}
\label{sec:applications}
We envision that \verb|WebEth| could be used for a variety of applications.
\paragraph{Web Content Monetization:}
With the growth in global Internet usage, hosting websites has become a lucrative business. As a result, new methods of monetizing electronic content have surfaced with time. Though some are more successful than others, all of them have associated issues. For instance, selling advertisement space is now resulting in declining revenue for website owners due to the advent of new technologies such as AdBlock \cite{Adblock}, Brave Browser \cite{BraveBrowser,decliningRevenue}; when coupled with an increased load time, browser slow-down, and placement challenges, online ads adversely affect user experience.  Thus, we envision that website content can be monetized through client-size coin mining, utilizing techniques such as those presented in this work. Note though that earning real cash requires a significant subscriber base or a large amount of time spent on the website, making this an ideal approach for video streaming/gaming websites.
% Another approach involves subscriptions, however, it is not very successful. Indeed, as this study finds, users are becoming increasingly unlikely to pay for content \cite{noSubscriptions}. Website owners also use pay-per-click Advertising, however an approach often leads to the content being split over an excessive number of pages, thereby leading to consumer frustration \cite{payPerClick}. Thus, we see that each approach has its own issues, be it with  with website owners or clients. Hence, it is important to strike a balance and create a solution that would be able to benefit both parties. Our web-based miner would solve this situation as it does not 
% \textbf{Web-Authentication Rate Limiting}: 
\paragraph{Web Authentication Rate Limiting:}
Another potential application relates to rate limiting of web-authentication.  Many tools are openly available for brute forcing web login pages~\cite{hydra,burpsuite}. Currently, website owners mitigate these attacks is by locking out a user for a certain amount of time after a fixed number of unsuccessful login attempts or presenting a captcha~\cite{recaptcha}.  
% While this approach works in theory, in today's fast-paced world, users tend to dislike waiting for even a few seconds ~\cite{usersDislikeWaiting}. 
Lock out presents a Denial of Service potential by locking out legitimate users as a consequence of an attack. 
Captcha techniques can be used for third-party value~\cite{von2008recaptcha} and have been successfully attacked through machine learning techniques~\cite{mlCaptcha} and crowdsourcing~\cite{captchaFarms}. 
% .~\trishita{CITEEE...}%AT - citation needed here!

% While it seems as though this approach is effective at face value, in reality, it does more harm than good as by introducing the risk of Denial of Service. This is because most brute force attacks are large scale and try millions of username/password combinations, which would consequently lockout a large number of user accounts. While this may prevent an attacker from successfully cracking passwords, it would also deny service to a lot of legitimate users whose accounts were being brute forced. This, amongst other issues, would definitely reflect badly on the website owner, and hence opens a whole new avenue for attack.   
We posit a more user-friendly approach to this problem involving embedding a Proof-of-Work computation in a web page, \emph{e.g.}, using \verb|WebEth|, that the user's browser needs to successfully solve in order to be able to login. The PoW would amplify the computational power needed for brute force attempts, thereby selectively thwarting any attacker that attempts to brute force the login \emph{without} significantly penalizing the legitimate user. \verb|WebEth| is an especially good candidate for such an implementation because one could manually set the difficulty to obtain a balance between user experience and security.

\paragraph{Proof of Web Traffic:}
Another use-case of \verb|WebEth| involves website advertisement companies. Today, website advertising sponsors decide on the remuneration for a website based on summarized server logs as a measure for site traffic. These logs can be manipulated by a website owner to generate the impression of a large amount of traffic ~\cite{webLogsManipulation} or by ad injectors~\cite{adinjection}. As a solution to this, \verb|WebEth| could be embedded by a website owner within the website, thereby making the site visitors compute PoW hashes. The advertiser would then ask the website owner to submit hashes that pass a certain difficulty threshold (i.e., the value of the hash being less than a certain number), and the larger the number of hashes that the website owner can provide, the more the remuneration the site receives. This would be more difficult for the website owners to fake since they would have to compute hashes themselves, an endeavor that might be more expensive than the potential ad payout.

\paragraph{Private Ethereum Test Networks:}
Finally, we would also like to note that Ethereum is an extremely flexible currency in the sense that it allows for private coin networks -- \emph{i.e.,} networks that do not mine the public Ethereum block-chain, but rather a private (and often smaller) instance of the cryptocurrency. \verb|WebEth| can be used on any such private network to serve the network owner's specific interests.

\section{Conclusion}
\label{sec:conclusion}
We have designed and implemented \verb|WebEth|, an open-source and  distributed web-based Ethereum miner, with potential applications toward monetizing electronic content, rate limiting, private test networks, user tracking for advertisers, and the like. \verb|WebEth| is standalone, implemented in both \verb|JavaScript| and \verb|WebAssembly|, and requires no external dependencies, meaning that both of these implementations can be readily embedded within many existing websites.  We have also provided analyses and experimental data to help in engineering our proposed applications.

% Furthermore, we provide an API that can be used by any implementation of Ethereum (\verb|geth| or Ethereum's implementation in \verb|C++|). We believe this can be a be especially viable in a private testnet, within a company for example, and with further research has the potential to make a real impact.

\paragraph{Future Work:}
Many interesting issues remain open.  For one, our current implementation is still slower than traditional mining methods. One way to speed this process up is to tap into the client machine's GPU. There is a \verb|JavaScript| library called WebCL that binds to the OpenCL library which allows \verb|JavaScript| to interact directly with the GPU to achieve better parallel performance. Knowing that Ethereum was created for GPU mining, it should provide a substantial improvement. 

The Ethereum Foundation is also currently developing Casper, a Proof-of-Stake algorithm, which has already been deployed in private testnets. Since Casper is open-source, it should be possible to create a Proof-of-Stake distributed browser miner implementation. However, users would most likely have to provide ``stakes" in order for such an implementation to be possible ~\cite{PoSproof}. Further research will be necessary to determine whether browser mining for Casper is viable or not, as the final form of Casper is still uncertain and exactly how much ``stake'' is required to successfully mine is unknown.


% conference papers do not normally have an appendix


% % use section* for acknowledgement
\section*{Acknowledgment}
The authors would like to thank Dennis Your for his contributions during the early stages of this research. This research was supported in part by NSF under grant CCF-1563753. Any
opinions, findings, and conclusions or recommendations expressed in this material
are those of the authors and do not necessarily reflect the views of the
NSF.

\begin{thebibliography}{1}
\bibitem{WebEth} Tiwari, Trishita, et al. ``WebEth.'' GitHub, 1.0, GitHub, 10 Apr. 2018, github.com/trishutiwari/web-ethereum-mining.

\bibitem{Adblock} Gundlach, Micheal. AdBlock browser extension. AdBlock. Software, 2009.

\bibitem{ethash}Matthew Wampler, et al. Ethash. Computer software. GitHub. Vers. 23.1. GitHub, 11 Jan. 2015. Web. 24 Feb. 2018. https://github.com/ethereum/ethash. 

\bibitem{BraveBrowser} Eich, Brendan and Brian Bondy. Brave Browser. Brave Software. Software, 2015.

\bibitem{decliningRevenue} Hern, Alex. ``Adblock Plus: the Tiny Plugin Threatening the Internet's Business Model.'' The Guardian, Guardian News and Media, 14 Oct. 2013, www.theguardian.com/technology/2013/oct/14/the-tiny-german-company-threatening-the-internets-business-model.

\bibitem{dagger-hashimoto} Buterin, Vitalik, et al. ``Ethereum/Wiki.'' GitHub, GitHub, 9 Feb. 2014, github.com/ethereum/wiki/blob/master/Dagger-Hashimoto.md. 

\bibitem{noSubscriptions} Rosenwald, Micheal. ``Digital News Consumers Unlikely to Pay for Content and Increasingly Block Ads.'' Columbia Journalism Review, Columbia Journalism Review, 15 June 2015, www.cjr.org/analysis/reuters\_digital\_news\_report.php.

\bibitem{payPerClick} Fessenden, Therese. ``Nielsen Norman Group.'' The Most Hated Online Advertising Techniques, Nielsen Norman Group, 4 June 2017, www.nngroup.com/articles/most-hated-advertising-techniques/.

\bibitem{celebEndorse} Awad, Amal. ``A Study in Scarlett: The Ethics of Celebrity Endorsement.'' – Opinion – ABC Religion \&Amp; Ethics (Australian Broadcasting Corporation), Amal Awad ABC Religion and Ethics, 30 Jan. 2014, www.abc.net.au/religion/articles/2014/01/31/3935443.htm.

\bibitem{scheduling}
Ramamritham, Krithi, and John A. Stankovic. ``Dynamic task scheduling in hard real-time distributed systems.'' IEEE software 1.3 (1984): 65.

\bibitem{parallel}
Shirazi, Behrooz A., Krishna M. Kavi, and Ali R. Hurson. Scheduling and load balancing in parallel and distributed systems. IEEE Computer Society Press, 1995.

\bibitem{orca}
Bal, Henri E., M. Frans Kaashoek, and Andrew S. Tanenbaum. ``Orca: A language for parallel programming of distributed systems.'' IEEE transactions on software engineering 18.3 (1992): 190-205.

\bibitem{WebFlow}
Bhatia, Dimple; Burzevski, Vanco; Camuseva, Maja; and Fox, Geoffrey C., ``WebFlow - A Visual Programming Paradigm for Web/Java Based Coarse Grain Distributed Computing'' (1997).
Northeast Parallel Architecture Center.

\bibitem{Cushing} Cushing, Reginald, et al. ``Distributed Computing on an Ensemble of Browsers.'' IEEE Internet Computing, IEEE, 1 Sept. 2013, www.computer.org/csdl/mags/ic/2013/05/mic2013050054.html.

\bibitem{randmemohash} Lerner, Sergio Demian. ``Strict Memory Hard Hashing Functions (Preliminary V0. 3, 01-19-14)."

\bibitem{coinhive}
The Coinhive Team. Coinhive browser extension. Coinhive. Software, 2017.

\bibitem{pow}
Laurie, Ben, and Richard Clayton. ``Proof-of-work proves not to work; version 0.2.'' Workshop on Economics and Information, Security. 2004.

\bibitem{casper}
Hertig, Alyssa. ``Ethereum's Big Switch: The New Roadmap to Proof-of-Stake.'' CoinDesk, CoinDesk, 16 May 2017, www.coindesk.com/ethereums-big-switch-the-new-roadmap-to-proof-of-stake/. 

\bibitem{pos}
Dmitry Buterin, et al. ``Proof of Work vs Proof of Stake: Basic Mining Guide.'' Blockgeeks, Blockgeeks, 24 July 2017, blockgeeks.com/guides/proof-of-work-vs-proof-of-stake/. 

% \bibitem{arc}
% The ArcticCoin Team. ArcticCoin crypto-currency. ArcticCoin. Software, 2015.

\bibitem{Monero} ``Monero - Secure, Private, Untraceable.'' Getmonero.org, The Monero Project, getmonero.org/.

\bibitem{Duda} Duda, Jerzy, and Wojciech Dłubacz. ``Distributed Evolutionary Computing System Based on Web Browsers with Javascript.'' ACM Digital Library, Springer-Verlag, dl.acm.org/citation.cfm?id=2451764.2451780.

\bibitem{traffic} The SimilarWeb Team. SimilarWeb LTD 2017. (https://www.similarweb.com/)

\bibitem{coinwarz}Coinwarz Ethereum Mining Calculator and Profit Calculator. Coinwarz 2017. (https://www.coinwarz.com/calculators/ethereum-mining-calculator)

\bibitem{PoSproof}Dale, Oliver. ``Beginner's Guide to Ethereum Casper Hardfork: What You Need to Know''. Blocknomi, 7 November 2017. (https://blockonomi.com/ethereum-casper/)

\bibitem{Ethmining}
Wood, Gavin. ``Ethereum: A secure decentralised generalised transaction ledger.'' Ethereum Project Yellow Paper 151 (2014): 1-32.

\bibitem{geth}Péter Szilágyi, et al. Geth. Computer software. GitHub. Vers. 1.8.1. GitHub, 22 Dec. 2013. Web. 24 Feb. 2018. https://github.com/ethereum/go-ethereum. 

\bibitem{etherscan}Etherscan The Ethereum Block Explorer. Etherscan 2017. (https://etherscan.io/charts)

\bibitem{remote} remoteStorage: An open protocol for per-user storage on the Web. (https://remotestorage.io/)

\bibitem{webAssembly}  W3C Team. WebAssembly. Program documentation. WebAssembly. Vers. 1.0. WebAssembly, 17 Mar. 2017. Web. 28 Mar. 2018. http://webassembly.org. 

\bibitem{wasmPerf} Zlatkov, Alexander. ``How JavaScript Works: A Comparison with WebAssembly.'' SessionStack Blog. SessionStack Blog, 21 Nov. 2017. Web. 28 Mar. 2018. https://blog.sessionstack.com/how-javascript-works-a-comparison-with-webassembly-why-in-certain-cases-its-better-to-use-it-d80945172d79. 

\bibitem{emscripten} Emscripten Community. Emscripten. Emscripten. Vers. 1.37.36. Emscripten, 11 Nov. 2012. Web. 28 Mar. 2018. http://kripken.github.io/emscripten\-site/docs/getting\_started/Tutorial.html. 

\bibitem{internetSpeed} Ookla. ``Speedtest Global Index – Monthly Comparisons of Internet Speeds from around the World.'' Speedtest Global Index, Ookla, 25 Mar. 2018, www.speedtest.net/global-index.

\bibitem{hydra}  Fogerlie, Garrett, director. Brute Force Website Login Attack Using Hydra - Hack Websites - Cyber Security. Brute Force Website Login Attack Using Hydra - Hack Websites - Cyber Security, YouTube, 24 Sept. 2013, www.youtube.com/watch?v=ZVngjGp-oZo. 

\bibitem{burpsuite} Mahmood, Osama. ``Brute Force Website Login Page Using Burpsuite –.'' SecurityTraning, SecurityTraning, 5 Feb. 2018, securitytraning.com/brute-force-website-login-page-using-burpsuite/. 

\bibitem{webLogsManipulation} Fox\-Brewster, Thomas. ``'Biggest Ad Fraud Ever': Hackers Make \$5M A Day By Faking 300M Video Views.'' Forbes, Forbes Magazine, 20 Dec. 2016, www.forbes.com/sites/thomasbrewster/2016/12/20/methbot\-biggest\-ad\-fraud\-busted/\#73f089a94899/ 

\bibitem{couponCollector} Neal, Peter. ``The Generalised Coupon Collector Problem.'' Journal of Applied Probability, vol. 45, no. 3, 2008, pp. 621\-629., doi:10.1239/jap/1222441818.
\bibitem{harmonicNumber} Guo, Bai-Ni \& Qi, Feng. (2011). Sharp bounds for harmonic numbers. Applied Mathematics and Computation. 218. 991-. 10.1016/j.amc.2011.01.089.

\bibitem{recaptcha} Google recaptcha, \url{https://www.google.com/recaptcha/intro/}.

\bibitem{von2008recaptcha} Von Ahn, Luis and Maurer, Benjamin and McMillen, Colin and Abraham, David and Blum, Manuel, ``Recaptcha: Human-based character recognition via web security measures'', Science, vol. 321, no. 5895, pp. 1465-1468, 2008.

\bibitem{adinjection} Thomas, Kurt, et al. ``Ad injection at scale: Assessing deceptive advertisement modifications.'' IEEE Symposium on Security and Privacy, 2015.

\bibitem{ethereum} ``Ethereum: A secure decentralised generalised transaction ledger''. G Wood. 2014. cryptopapers.net Ethereum Project Yellow Paper.

\bibitem{keccak} Bertoni, Guido, et al. ``Keccak.'' Annual International Conference on the Theory and Applications of Cryptographic Techniques. Springer, Berlin, Heidelberg, 2013.

\bibitem{asics} Taylor, Michael Bedford. ``The Evolution of Bitcoin Hardware.'' Computer 50.9 (2017): 58-66.

\bibitem{js} Peyrott, Sebastián. ``A Brief History of JavaScript.'' Auth0 - Blog, Auth0, 16 Jan. 2017, auth0.com/blog/a-brief-history-of-javascript/. 

\bibitem{basicAttentionToken} Brave Software. ``Basic Attention Token.'' Basic Attention Token, 1.0, Brave Software, 13 Mar. 2018, basicattentiontoken.org/. 

\bibitem{mlCaptcha} Geitgey, dam. ``How to Break a CAPTCHA System in 15 Minutes with Machine Learning.'' Medium, Medium, 13 Dec. 2017, medium.com/@ageitgey/how-to-break-a-captcha-system-in-15-minutes-with-machine-learning-dbebb035a710. 

\bibitem{captchaFarms} Danchev, Dancho. ``Inside India's CAPTCHA Solving Economy.'' ZDNet, ZDNet, 4 Dec. 2015, www.zdnet.com/article/inside-indias-captcha-solving-economy/.

\bibitem{erc20} ``ERC20 Token Standard,'' \url{https://theethereum.wiki/w/index.php/ERC20\_Token\_Standard}.
\end{thebibliography}

\addtolength{\textheight}{-7cm}
% \balance


% that's all folks
\end{document}